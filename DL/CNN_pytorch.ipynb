{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper parameters\n",
    "num_epochs = 25\n",
    "num_classes = 10\n",
    "batch_size = 32\n",
    "num_workers=4\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Define transformations for the training set, flip the images randomly, crop out and apply mean and std normalization\n",
    "train_transformations = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32,padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "# Define transformations for the test set\n",
    "test_transformations = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "\n",
    "])\n",
    "\n",
    "# CIFAR10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data/',\n",
    "                                           train=True, \n",
    "                                           transform=train_transformations,\n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data/',\n",
    "                                          train=False, \n",
    "                                          transform=test_transformations)\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True,\n",
    "                                           num_workers=num_workers)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False,\n",
    "                                          num_workers=num_workers)\n",
    "\n",
    "\"\"\"\n",
    "CIFAR10 input image: 3 * 32 * 32\n",
    "\"\"\"\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=1, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1),\n",
    "            nn.ReLU())\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1),\n",
    "            nn.ReLU())\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=8)\n",
    "        self.fc = nn.Linear(1*1*128, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        # print(out.size())\n",
    "        out = self.layer2(out)\n",
    "        # print(out.size())\n",
    "        out = self.layer3(out)\n",
    "        out = self.avgpool(out)\n",
    "        # print(out.size())\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "class ConvNet_with_bn(nn.Module):\n",
    "    \"\"\"\n",
    "    - Add batch normalization layer right after each convolutional layers.\n",
    "    - Test Accuracy of the model on the 10000 test images: 74.73 %\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ConvNet_with_bn, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1),\n",
    "            nn.BatchNorm2d(num_features=128),\n",
    "            nn.ReLU())\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1),\n",
    "            nn.BatchNorm2d(num_features=128),\n",
    "            nn.ReLU())\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=8)\n",
    "        self.fc = nn.Linear(1*1*128, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        # print(out.size())\n",
    "        out = self.layer2(out)\n",
    "        # print(out.size())\n",
    "        out = self.layer3(out)\n",
    "        out = self.avgpool(out)\n",
    "        # print(out.size())\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "class ConvNet_deep(nn.Module):\n",
    "    \"\"\"\n",
    "    - Using smaller filter and deeper layers.\n",
    "    - Test Accuracy of the model on the 10000 test images: 83.2 %.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ConvNet_deep, self).__init__()\n",
    "        self.layer1 = nn.Sequential( # 3*32*32 -> 64*16*16\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential( # 64*16*16 -> 128*8*8\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer3 = nn.Sequential( # 128*8*8 -> 256*4*4\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer4 = nn.Sequential( # 256*4*4 -> 512*4*4\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(num_features=512),\n",
    "            nn.ReLU())\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=4) # 512*4*4 -> 512*1*1\n",
    "        self.fc = nn.Linear(1*1*512, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "def model_train(model=None):\n",
    "    # Loss and optimizer\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    loss_lst = []\n",
    "    # Train the model\n",
    "    total_step = len(train_loader)\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            if (i+1) % 200 == 0:\n",
    "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                    .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "        epoch_loss = total_loss / len(train_loader.dataset)\n",
    "        loss_lst.append(epoch_loss)\n",
    "\n",
    "    # Test the model\n",
    "    model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "    # Save the model checkpoint\n",
    "    torch.save(model.state_dict(), 'model.ckpt')\n",
    "\n",
    "    loss_lst = [l for l in loss_lst]\n",
    "\n",
    "    # Draw loss-epoch graph.\n",
    "    def draw_loss():\n",
    "        ts = time.gmtime()\n",
    "        plt.title(\"Loss vs. Number of Training Epochs\")\n",
    "        plt.xlabel(\"Training Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.plot(range(1,num_epochs+1),loss_lst)\n",
    "        plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "        plt.legend()\n",
    "        plt.savefig('loss-epoch{}.png'.format(time.strftime(\"%Y-%m-%d %H:%M:%S\", ts)))\n",
    "\n",
    "    draw_loss()\n",
    "\n",
    "    # Visualize conv filter\n",
    "    def vis_kernels():\n",
    "        kernels = model.layer1[0].weight.detach()\n",
    "        print(kernels.shape)\n",
    "        fig, axarr = plt.subplots(4, 16, figsize=(15, 15))\n",
    "        for x in range(4):\n",
    "            for y in range(16):\n",
    "                kernel_id = x * 4 + y\n",
    "                kernel = kernels[kernel_id]\n",
    "                # print(kernel.shape)\n",
    "                axarr[x, y].imshow(transforms.ToPILImage()(kernel), interpolation=\"bicubic\")\n",
    "\n",
    "# model = ConvNet(num_classes).to(device)\n",
    "# model_train(model)\n",
    "\n",
    "model_bn = ConvNet_with_bn(num_classes).to(device) # model with batch normalization layer between each hidden layers. \n",
    "model_train(model_bn)\n",
    "\n",
    "# model_deep = ConvNet_deep(num_classes).to(device) \n",
    "# model_train(model_deep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
