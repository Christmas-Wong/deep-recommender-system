# 笔记

- [Kaggle Jupyter技巧总结：经典机器学习模型，Pipeline, GridSearch, Ensemble等](https://github.com/chocoluffy/kaggle-notes/tree/master/Kaggle)
- [Softmax的numpy实现, 以及SGD、minibatch](https://github.com/chocoluffy/kaggle-notes/blob/master/DL/Softmax.md)

# 总结

## Typical models (classification)

for supervised learning classification (such as the current problem) include techniques such as:

- logistic regression and penalized logistic regression
- linear discriminant analysis
- decision trees (CART, CHAID, C5.0)
- random forests
- gradient boosted machines
- support vector machines
- neural networks (and deep learning)

## (regression) continuous outcome

for supervised learning for continuous outcome problems (e.g., the second problem) include techniques such as:

- linear regression, ridge regression, lasso, elastic net
- partial least squares regression(PLSR), principal component regression(PCR)
- decision trees (CART, CHAID, C5.0)
- multiple adaptive regression splines
- random forests
- gradient boosted machines
- support vector machine regression
- neural networks (and deep learning)
